AI 기술 동향 및 주요 연구 프로젝트 브리핑

요약

본 브리핑 문서는 최신 인공지능(AI) 기술의 발전, 근본적인 과제, 그리고 대규모 융합 연구 프로젝트의 현황을 종합적으로 분석한다. 주요 내용은 다음과 같다:

1. 차세대 시각-언어 모델(VLM)의 발전: 딥마인드의 Flamingo 모델은 단 몇 개의 예시만으로 새로운 시각 및 언어 작업을 학습하는 '퓨샷 러닝(few-shot learning)'에서 새로운 SOTA(State-of-the-Art)를 달성했다. 이는 사전 훈련된 강력한 비전 및 언어 모델을 혁신적인 아키텍처로 연결하여, 수천 배 더 많은 데이터로 미세조정(fine-tuning)된 모델의 성능을 능가하는 성과를 보였다.
2. AI의 미래와 근본적 과제에 대한 담론:
  * 얀 르쿤(Yann LeCun) 교수는 현재 AI, 특히 대규모 언어 모델(LLM)이 물리적 세계에 대한 이해와 추론 능력이 부족하다고 지적하며, 예측을 통해 세계의 추상적 표현을 학습하는 **월드 모델(World Model)**과 **JEPA(Joint Embedding Predictive Architecture)**를 차세대 AI의 핵심으로 제시했다.
  * 최예진(Yejin Choi) 교수는 LLM의 창의성, 다원주의, 역설 등 **'LLM의 수수께끼'**를 탐구했다. 그녀는 LLM의 창의성이 기존 데이터의 조합(내삽)에 머무를 가능성을 제기하고, 단일 가치 체계로 모델을 정렬하는 것의 위험성을 경고하며 다원적 접근법(overtone, steerable, distributional)을 제안했다. 또한, '생성할 수 있는 것을 이해하지 못하는' 생성형 AI의 역설을 지적하며 모델 능력에 대한 깊은 이해를 촉구했다.
3. 딥러닝 모델의 내재적 특성 분석: 심층 신경망 내부에 **'터널 효과(Tunnel Effect)'**가 존재함이 밝혀졌다. 모델의 초기 레이어에서 데이터의 선형 분리 가능한 표현이 대부분 형성된 후, 중간 레이어들(터널)은 성능 향상에 거의 기여하지 않으며, 이는 오히려 분포 외(out-of-distribution) 데이터에 대한 성능 저하를 유발할 수 있다.
4. 대규모 AI 융합 연구 프로젝트:
  * 뇌과학 파운데이션 모델(NeuroX-Fusion): 뇌영상(MRI, PET), 뇌파(EEG), 멀티오믹스 등 방대한 데이터를 통합하여 약 1,550억 개 파라미터 규모의 '디지털 트윈 브레인'을 구축하는 프로젝트가 추진 중이다. LLM을 중심으로 각 모달리티별 파운데이션 모델을 정렬하여, 치매와 같은 뇌 질환의 예측 및 개인 맞춤형 솔루션을 제공하는 것을 목표로 한다.
  * 소아 발달장애 AI 모델 개발: 뇌영상, 유전체, 행동표현형 등 멀티모달 데이터를 통합하여 발달장애의 조기 진단 및 임상 경과 예측을 위한 바이오마커를 발굴하는 연구가 진행되고 있다. 파운데이션 모델을 기반으로 샘플 효율적 학습, 연합 학습, 불확실성 정량화 등 최신 AI 방법론을 적용하여 임상적 실용성을 갖춘 모델 개발을 목표로 한다.

1. 차세대 시각-언어 모델: Flamingo

딥마인드에서 개발한 Flamingo는 소수의 예제만으로 새로운 작업을 신속하게 학습할 수 있는 시각-언어 모델(Visual Language Model, VLM) 제품군이다. 이 모델은 멀티모달 기계 학습 연구의 오랜 난제였던 효율적인 적응 능력에서 중요한 돌파구를 마련했다.

핵심 개념 및 아키텍처

Flamingo는 기존의 강력한 사전 훈련된 비전 전용 모델과 언어 전용 모델을 동결(frozen) 상태로 유지하면서, 이 둘을 연결하는 새로운 아키텍처 구성 요소를 추가하여 훈련하는 방식을 채택했다. 이는 막대한 계산 비용이 소요된 사전 훈련 지식을 그대로 보존하면서 시각 정보를 언어 모델에 효과적으로 조건화하기 위함이다.

주요 아키텍처 혁신은 다음과 같다:

* Perceiver Resampler: 다양한 크기의 대규모 시각 특징 맵(이미지 또는 비디오에서 추출)을 소수의 고정된 시각적 토큰(64개)으로 변환하는 모듈이다. 이를 통해 계산 복잡성을 줄이면서도 비전 인코더와 언어 모델을 효율적으로 연결한다.
* GATED XATTN-DENSE 레이어: 사전 훈련되어 동결된 언어 모델(LM) 블록들 사이에 새로운 교차 어텐션(cross-attention) 레이어를 삽입한다. 이 레이어는 언어 특징을 쿼리(query)로, 시각 토큰을 키(key)와 값(value)으로 사용하여 시각 정보를 텍스트 생성 과정에 통합한다. 훈련 초기 안정성을 위해 tanh-gating 메커니즘을 적용하여, 초기에는 새로 추가된 레이어가 모델 출력에 영향을 미치지 않도록 설계되었다.

주요 성능 및 기여

Flamingo는 이미지 캡셔닝, 시각적 질의응답(VQA), 비디오 이해 등 광범위한 16개의 멀티모달 벤치마크에서 퓨샷 러닝(few-shot learning)으로 새로운 SOTA를 달성했다.

* 퓨샷 성능: 단 32개의 작업별 예제만으로 16개 벤치마크 중 6개에서 수십만 개의 데이터로 미세조정(fine-tuning)된 기존 SOTA 모델의 성능을 능가했다.
* 미세조정 성능: 더 많은 데이터로 미세조정할 경우, VQAv2, VATEX, HatefulMemes 등 5개의 추가 벤치마크에서도 새로운 SOTA를 기록했다.
* 다중 시각 입력 처리: 텍스트와 이미지/비디오가 임의로 혼합된 시퀀스를 원활하게 처리할 수 있으며, 훈련 시에는 최대 5개의 이미지만 사용했음에도 불구하고 평가 시에는 최대 32개의 이미지/텍스트 쌍을 활용하여 성능을 향상시킬 수 있다.

이러한 성과는 대규모의 작업별 주석 데이터 없이도 단일 모델을 다양한 시각 및 언어 작업에 신속하게 적용할 수 있는 실용적인 경로를 제시했다는 점에서 의의가 크다.

모델	파라미터	기반 LM
Flamingo-3B	32억	Chinchilla 1.4B
Flamingo-9B	93억	Chinchilla 7B
Flamingo-80B	800억	Chinchilla 70B

2. AI의 미래와 근본적 과제

Global AI Frontiers Symposium 2025와 최예진 교수의 강연은 현재 AI 기술, 특히 LLM의 한계를 조명하고 미래 AI가 나아가야 할 방향에 대한 심도 있는 논의를 제공했다.

2.1. 얀 르쿤의 비전: 월드 모델과 JEPA

얀 르쿤 교수는 현재의 자기회귀(autoregressive) LLM이 텍스트 데이터에 대한 방대한 학습에도 불구하고, 실제 세계에 대한 이해, 상식, 추론 및 계획 능력이 결여되어 있다고 비판했다. 그는 이를 극복하기 위한 대안으로 **월드 모델(World Model)**의 개념을 강조했다.

* 월드 모델: 특정 행동(action)이 주어졌을 때 세상의 상태가 어떻게 변할지 예측하는 내부 모델이다. 이를 통해 AI 에이전트는 여러 행동 시퀀스의 결과를 시뮬레이션하고, 목표 달성을 위한 최적의 계획을 수립할 수 있다.
* JEPA (Joint Embedding Predictive Architecture): 월드 모델을 훈련시키기 위한 핵심 아키텍처다. JEPA는 비디오의 다음 프레임을 픽셀 수준에서 예측하는 대신, 입력(예: 비디오의 일부)을 추상적인 표현 공간(representation space)으로 인코딩한 후, 이 공간 내에서 미래의 표현을 예측하도록 학습한다. 이는 불필요한 세부 사항을 제거하고 세상의 본질적인 구조를 학습하게 하여, 불가능에 가까운 픽셀 단위 예측의 한계를 극복하는 방법이다.

르쿤 교수는 JEPA 기반의 월드 모델이 인간이나 동물처럼 세상을 이해하고 효율적으로 학습하며 계획을 세우는, 진정으로 지능적인 시스템으로 가는 길이라고 주장했다.

2.2. 최예진의 통찰: LLM의 수수께끼

최예진 교수는 LLM이 보여주는 놀라운 능력 이면에 존재하는 근본적인 수수께끼들을 제시하며, AI에 대한 보다 비판적이고 다각적인 접근을 촉구했다.

창의성 (Creativity)

* 헤밍웨이 사고 실험: 헤밍웨이의 작품과 그의 영향을 받은 모든 글을 제외하고 인터넷의 모든 텍스트로 LLM을 훈련시켰을 때, 과연 헤밍웨이 스타일의 독창적인 문체를 창조해낼 수 있을까? 이는 LLM의 창의성이 기존 데이터의 조합과 보간(interpolative novelty)에 불과한지, 아니면 진정한 외삽(extrapolative novelty)이 가능한지에 대한 질문이다.
* 창의성 지수(Creativity Index): LLM이 생성한 텍스트가 웹 데이터와 얼마나 중복되지 않는지를 측정하는 '창의성 지수'를 제안했다. 분석 결과, LLM이 생성한 유창해 보이는 많은 문구들이 실제로는 웹상에 그대로 또는 거의 유사하게 존재하는 것으로 나타나, LLM의 창의성이 표면적 수준에 머무를 수 있음을 시사했다.

다원주의 (Pluralism)

* 단일 가치 정렬의 위험: 현재의 강화학습(RLHF) 기반 정렬은 암묵적으로 단일한 혹은 다수의 가치 체계에 모델을 맞추려 한다. 이는 인간 사회의 다양한 가치와 선호를 반영하지 못하고, 특정 집단의 관점만을 강화하는 결과를 낳을 수 있다.
* 다원적 정렬: 이에 대한 대안으로 세 가지 접근법을 제안했다.
  1. Overtone Pluralism: 특정 질문에 대해 가능한 모든 합리적인 관점(예: 공리주의, 의무론)을 제시한다.
  2. Steerable Pluralism: 사용자가 자신의 가치 체계를 지정하면, 모델이 그에 맞춰 답변을 제어하도록 한다.
  3. Distributional Pluralism: 의사결정 시, 다수의 의견뿐만 아니라 소수의 의견까지 포함하여 인간의 의견 분포를 모방하여 결정을 내린다.

역설 (Paradoxes)

* 생성형 AI 역설: "만들 수 있는 것을 이해하지 못할 수 있다(What it can create, it may not understand)." 예를 들어, AI는 '테이블 위에서 플랭크 하는 우주비행사' 이미지를 사실적으로 생성하지만, 생성된 이미지들 중 어느 것이 프롬프트를 정확히 따랐는지 스스로 판단하지 못할 수 있다.
* 반전 저주(Reversal Curse): 모델이 'A는 B이다'를 학습해도 'B는 A이다'를 추론하지 못하는 현상. '톰 크루즈의 어머니는 메리 리 파이퍼이다'를 알아도, '메리 리 파이퍼는 누구인가?'라는 질문에 답하지 못하는 경우가 있다.

이러한 역설들은 LLM이 진정한 의미의 이해보다는 패턴 매칭에 의존하고 있음을 보여준다.

2.3. AI 민주화와 국제 협력

심포지엄의 여러 연사들은 AI 기술이 소수의 거대 기업이나 국가에 집중되는 것을 경계하며 AI의 민주화와 국제 협력의 중요성을 역설했다.

* 데이터와 문화의 다양성: 전 세계의 모든 데이터, 언어, 문화, 가치 체계를 단일 기업이 확보하는 것은 불가능하다. 따라서 오픈소스 플랫폼과 국제 협력을 통해 다양한 데이터를 활용하는 것이 장기적으로 상업적 폐쇄형 모델보다 우위에 설 것이다.
* 협력의 장애물: 지정학적 긴장, 그리고 각 국가가 AI 분야에서 모든 것을 잘하려고 하는 '만능주의'가 실질적인 협력을 저해하는 요인으로 지적되었다. 효과적인 협력을 위해서는 각자의 강점과 약점을 인정하고 상호 보완적인 관계를 구축해야 한다.
* 혁신을 위한 문화: 최예진 교수는 GPU와 인재 외에, 실패를 용인하고 창의적인 시도를 장려하는 **'문화와 사고방식(mindset and culture)'**이 혁신의 제3의 기둥이라고 강조했다. 권위주의적 문화를 탈피하고 연구자들에게 진정한 자신감을 심어주는 환경 조성이 필수적이다.

3. 딥러닝 모델의 내재적 특성 분석: 터널 효과

최신 연구는 표준적인 심층 신경망(MLP, VGG, ResNet 등) 아키텍처 내에서 **'터널 효과(The Tunnel Effect)'**라는 현상을 발견했다. 이는 모델의 깊이가 항상 성능 향상으로 이어지지 않으며, 특정 구간에서는 오히려 일반화 성능을 저해할 수 있음을 시사한다.

현상 정의

* 추출기(Extractor)와 터널(Tunnel): 딥러닝 모델은 기능적으로 두 부분으로 나눌 수 있다.
  * 추출기: 모델의 초기 레이어들로, 입력 데이터로부터 선형적으로 분리 가능한(linearly-separable) 특징 표현(representation)을 구축하는 역할을 주로 수행한다. 이 구간에서는 선형 프로빙(linear probing) 정확도가 급격히 상승한다.
  * 터널: 추출기 이후의 중간 레이어들로, 이 구간에서는 선형 프로빙 정확도가 거의 향상되지 않거나 정체된다. 즉, 이미 형성된 표현을 크게 바꾸지 않고 거의 그대로 전달하는 역할을 한다.

터널 효과의 특징 및 영향

* 높은 표현 유사성: 터널 구간의 레이어들은 CKA(Centered Kernel Alignment) 유사도 측정 결과, 서로 매우 유사한 표현을 가지는 것으로 나타났다. 이는 정보의 추가적인 가공이 거의 이루어지지 않음을 의미한다.
* 수치적 랭크(Numerical Rank) 감소: 터널 구간에서는 표현 행렬의 수치적 랭크가 감소하는 경향을 보인다. 이는 표현의 '축퇴(degeneracy)'가 심화되어 표현 공간이 압축되고 있음을 의미한다.
* 분포 외(Out-of-Distribution, OOD) 성능 저하: 터널 효과는 모델의 일반화 능력에 부정적인 영향을 미친다. 훈련 데이터 분포(in-distribution)에서는 터널이 큰 영향을 미치지 않을 수 있지만, 훈련 데이터와 다른 분포의 데이터를 처리할 때 터널 구간에서 성능이 급격히 저하되는 현상이 관찰되었다. 이는 터널이 훈련 데이터에 과적합된 표현을 강화하기 때문으로 분석된다.

이 발견은 모델의 깊이를 무조건 늘리는 것이 최선이 아닐 수 있으며, 모델 압축이나 OOD 일반화 성능 향상을 위해 터널 구간의 역할을 재고해야 할 필요성을 제기한다.

4. 대규모 AI 융합 연구 프로젝트: 뇌과학 및 발달장애

AI, 특히 파운데이션 모델 기술이 뇌과학 및 의료 분야와 결합하여 인간의 인지와 질병을 이해하려는 대규모 융합 연구가 활발히 추진되고 있다. 이는 방대한 멀티모달 생체 데이터를 통합 분석하여 기존에 불가능했던 정밀 예측 및 개인 맞춤형 솔루션을 제공하는 것을 목표로 한다.

4.1. NeuroX-Fusion: 인지예비능 예측을 위한 통합 파운데이션 모델

이 프로젝트는 뇌영상(MRI, PET), 뇌파(EEG), 멀티오믹스(유전체, 대사체 등), 임상 문헌 등 다양한 데이터를 LLM의 의미론적 공간에서 융합하여, 약 1,550억 개 파라미터 규모의 통합 파운데이션 모델(BOM, Brain-Omics Model)을 구축하는 것을 목표로 한다.

세부 목표 및 기술 전략

1. 멀티모달 뇌영상 FM (92B): sMRI, dMRI, fMRI, PET 등 4가지 뇌영상 데이터를 통합하는 920억 파라미터 모델을 개발한다. 각 모달리티별 인코더를 학습하고, 교차 어텐션 어댑터를 통해 170억 파라미터 규모의 LLM과 정렬한다.
2. 멀티모달 뇌파 FM (50B): EEG, ECoG 등 뇌파 데이터를 처리하는 330억 파라미터 인코더를 개발하고, 이를 170억 LLM과 정렬하여 500억 파라미터 모델을 구축한다.
3. 멀티오믹스 FM (47B): 유전체(WGS) 등 멀티오믹스 데이터를 처리하는 300억 파라미터 인코더를 개발하고, 이를 170억 LLM과 정렬한다.
4. 통합 뇌-멀티오믹스 FM (BOM, 155B): 위에서 개발된 각 모달리티별 FM들을 LLM을 매개로 최종 융합하여 1,550억 파라미터 규모의 통합 모델을 완성한다. 이후 한국인 종단 데이터(GARD)로 미세조정하여 '인지예비능' 예측 및 개인 맞춤형 솔루션 제안 능력을 고도화한다.

핵심 기술

* LLM 중심 통합: LLM을 공통의 잠재 공간(latent space)으로 사용하여, 직접적인 쌍(pair)이 없는 이종 모달리티 데이터(예: 특정인의 뇌영상과 다른 사람의 유전체 데이터) 간의 '창발적 정렬(emergent alignment)'을 유도한다.
* 전문가 혼합(MoE, Mixture-of-Experts): 모델 규모를 효율적으로 확장하기 위해 MoE 아키텍처를 채택한다.
* 대규모 훈련 안정화: 미국 에너지부(DOE)의 Aurora, Frontier와 같은 리더십급 슈퍼컴퓨터를 활용하며, µTransfer와 같은 기술로 대규모 모델 훈련의 불안정성 문제를 해결한다.

4.2. 소아 발달장애 바이오마커 발굴 프로젝트

이 연구는 증가하는 발달장애(자폐스펙트럼장애(ASD), 전반적 발달지연(GDD) 등) 문제 해결을 위해, 멀티모달 데이터(뇌영상, 오믹스, 영상 기반 행동 데이터)를 통합하는 AI 파운데이션 모델을 개발하여 조기 진단 및 임상 경과 예측 바이오마커를 발굴하는 것을 목표로 한다.

연구 내용 및 단계

1. 1단계: 플랫폼 구축 및 바이오마커 후보 제시
  * 고품질 멀티모달 데이터 플랫폼 구축: 국내외 공공 데이터 및 분당차병원, 충남대학교병원 등의 임상 데이터를 수집, 정제, 표준화하여 글로벌 데이터 공유 플랫폼(예: brainlife.io)을 구축한다.
  * 모달리티별 AI 모델 개발 및 바이오마커 후보군 도출: 기존 AI 모델링과 생물정보학 분석을 통해 각 데이터(뇌영상, 오믹스, 행동 등)에서 바이오마커 후보를 제시한다.
2. 2단계: 통합 AI 모델 개발 및 바이오마커 검증
  * 대규모 파운데이션 모델 기반 통합 AI 모델 개발: 1단계에서 구축한 데이터를 기반으로 뇌영상-오믹스-행동-임상 데이터를 모두 통합하는 파운데이션 모델을 개발한다.
  * 실증적 검증: 전향적 코호트 데이터를 추가 수집하여 개발된 바이오마커와 AI 모델의 임상적 유효성을 평가한다.

극복 과제 및 해결 방안

* 적은 샘플 문제: 의료 데이터의 특성상 샘플 수가 부족한 문제를 해결하기 위해, 잠재 공간 최적화(LSO)와 같은 샘플 효율적 학습 알고리즘을 도입한다.
* 데이터 보안 및 일반화: 민감한 임상 데이터를 기관 외부로 공유하지 않으면서도 다양한 기관의 데이터를 학습에 활용하기 위해 **연합 학습(federated learning)**을 적용한다.
* 모델의 신뢰성: AI 모델의 예측에 대한 신뢰도를 확보하기 위해, 예측 결과의 불확실성을 정량화하는 기술을 도입하여, 모델이 확신하지 못하는 경우를 식별하고 임상적 의사결정을 보조하도록 한다.

사업화 계획

연구 개발 결과물인 멀티모달 AI 모델 및 데이터를 기반으로, 공동연구개발기관인 **루먼랩(주)**가 사업화를 주도한다. 소프트웨어 의료기기, 디지털 치료제, 디지털 관리 플랫폼 등을 개발하여 국내외 병의원 및 교육기관을 대상으로 사업을 전개할 계획이다. 세계 디지털 치료제 시장은 2028년 약 22조 원 규모로 성장이 예상되며, 본 프로젝트는 해당 시장 진출을 목표로 한다.
