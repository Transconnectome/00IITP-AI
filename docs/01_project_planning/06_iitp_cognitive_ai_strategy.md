# IITP(인공지능) — 인지·뇌 기반 통합지능 연구전략 (초안)

대상: `docs/00_task_description/raw/2-1. 인공지능.pdf`의 **2026-인공지능-010~014(병렬형)**  
목표: “감각-의미화-기억-학습-추론”을 통합한 **인지모사 통합지능 원천기술** + **벤치마크/지표/데이터** 패키지 제안

---

## 1) 어떤 과제로 들어갈까? (선택지)

- **옵션 A (가장 정합)**: `2026-인공지능-010` **총괄(주관)** + 011~014를 컨소시엄으로 병렬 수행
  - 장점: SNU Connectome의 “뇌 기반 통합” 스토리를 그대로 살릴 수 있음(벤치마크/데이터 연계 포함)
  - 리스크: 컨소시엄 구성/통합 운영 부담이 큼

- **옵션 B (현실적)**: 011~014 중 1개를 **세부(주관)**로 수행 + 010 총괄 팀에 연계
  - 장점: 범위를 줄여 “강한 1개”로 승부
  - 단점: 통합 스토리의 소유권이 약해질 수 있음

---

## 2) 연구 컨셉 (SNU Connectome 톤)

핵심 컨셉은 “LLM을 더 크게”가 아니라:

- **뇌의 구조**
- **뇌의 학습 규칙(국소/보상/예측)**
- **기억(사건 분절·망각/강화·의미기억)**
- **주의/다중감각 통합(불완전/모호한 환경에서 강건성)**
- **메타인지(자기 검증 루프)**

를 결합해 **적은 데이터/적은 자원/긴 시간**에서 “적응적 추론”을 달성하는 것입니다.

---

## 3) 통합 아키텍처 제안(초안)

### Core loop

1. **인지적 수집(Cognitive acquisition)**: 목표/주의 기반으로 필요한 감각/데이터만 선택
2. **의미화(Semantic integration)**: 시공간·개념 관계를 “의미 연결망”으로 조직
3. **기억(Memory)**: 사건 분절 + 맥락 유지 + 의미기억 일반화 + 중요도 기반 망각/강화
4. **학습(Learning)**: 국소 신호/보상/예측 기반 업데이트(지속학습·에너지 효율)
5. **추론/계획(Reasoning)**: 계층적 재계획 + 개념 확장 + 메타인지 자기검증

### SNU Connectome 차별점(핵심 한 줄)

> **connectome-informed inductive bias**로 “통합지능의 구조”를 설계하고, 벤치마크로 증명한다.

---

## 4) WP(Work Packages) 초안 (010~014에 1:1 매핑)

- **WP0 (총괄 공통)**: 통합 시나리오 + 데이터 연계 + 벤치마크/지표 설계
  - 산출: 통합 벤치마크 v1, 성능지표(적응/창의/일관성/환각/설명/에너지), 공개 데이터/코드 정책

- **WP1 (010/세부1)**: 다층적 상황 이해 + 개념 확장 + 메타인지 기반 통합 추론
  - 포인트: “환각 최소화/설명가능성”을 KPI로 정면 대응

- **WP2 (011/세부2)**: 생물학적 학습원리 기반 차세대 학습(국소·보상·예측)
  - 포인트: 데이터 효율/지속학습/적응/에너지 효율을 동시 최적화

- **WP3 (012/세부3)**: 사건기반 기억(working/long-term/semantic) + 망각/강화 + 멀티모달 회상
  - 포인트: “의미기억”과 “장기 맥락 유지”를 벤치마크로 증명

- **WP4 (013/세부4)**: 다중감각 통합 + 개념 주도(top-down) 감각 처리 + 선택적 주의
  - 포인트: 시각-언어를 넘어서 물리감각(촉각/고유/전정) 포함한 강건성

- **WP5 (014/세부5)**: 인지 기반 데이터 의미화/표현(주의·목표 기반 수집, 의미 연결망, 추상화)
  - 포인트: “데이터를 줄이면서 더 잘” — 의미 기반 압축/요약/동적 갱신

---

## 5) KPI/벤치마크(제안서에 넣을 형태)

아래는 “설명서가 요구하는 방향”을 직접 숫자로 만들기 위한 틀입니다.

- **적응적 추론**: 환경/목표 변화 시 성능 유지 + 재계획 성공률
- **개념 확장/창의적 문제 해결**: 기존 지식 재구성 기반의 신규 해결책 생성률(사람 평가 + 자동 지표 혼합)
- **환각(Hallucination) 감소**: 자기 검증 루프 도입 전/후 환각률, 근거 제시율, 오류 수정율
- **지속학습**: 장기 시나리오에서 망각(Backwards transfer) 최소화 + 축적(Forward transfer) 최대화
- **에너지/연산 효율**: FLOPs/토큰, 메모리, 추론 지연, (가능시) 전력 측정/추정 지표
- **기억 품질**: 사건 분절 정확도, 장기 맥락 유지력, 의미기억 일반화, 멀티모달 회상
- **감각 강건성**: 모호/결손/노이즈 환경에서 멀티모달 통합 이득(uni-modal 대비)
- **데이터 의미화**: 중복·불필요 데이터 감소율, 의미 연결망 품질, 성능 유지/향상

---

## 6) “Neuromorphic까지” 연결하는 설계 원칙(제안서용)

즉시 HW를 하자는 게 아니라, **나중에 가기 쉬운 알고리즘/표현**을 지금부터 선택합니다.

- 국소 업데이트(Plasticity), 스파스 활성(Attention/Memory gating), 이벤트 기반 감각 처리
- 동적 메모리/주의 제어(정적 트랜스포머보다 neuromorphic 친화)
- 평가 지표에 “에너지/지연”을 처음부터 포함

---

## 7) 바로 다음 액션(레포에서 할 일)

- `docs/00_task_description/summary/`를 기반으로, `templates/kpi_mapping.md`에 010~014 매핑 작성
- `docs/01_project_planning/03_work_packages.md`에 WP0~5를 “연차별 마일스톤”으로 구체화
- `docs/03_proposal/outline.md`를 “평가항목 중심”으로 재배치(특히 벤치마크/지표/통합 시나리오 강조)


